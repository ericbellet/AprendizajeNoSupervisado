---
title: "Aprendizaje No Supervisado"
author: "Eric Bellet"
date: "2 de Abril de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo=FALSE, results='hide', include=FALSE}
install = function(pkg)
{
  # Si ya está instalado, no lo instala.
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg)
    if (!require(pkg, character.only = TRUE)) stop(paste("load failure:", pkg))
  }
}

#Instalo automaticamente los paquetes.
install('rgl')
install('FactoMineR')
install('pROC')

#Cargo las librerias.
library(rgl)
library(FactoMineR)
library(pROC)

######################################MODIFICAR######################################
setwd("C:/Users/Eric/Desktop/AprendizajeNoSupervisado")
```
# Introducción

  El proceso de aprendizaje cuando desconocemos la columna clase se denomina en la literatura **aprendizaje no supervisado**. En algunos de estos casos, podemos aplicar algoritmos que nos permitan encontrar, de existir, estructuras que denominamos clústers para que, una vez encontrados, podamos analizarlos uno a uno hasta conseguir características de relevancia que nos permitan solucionar el problema planteado originalmente. 
  
  Este subconjunto de tareas donde podemos encontrar estructuras con alguna relación se denomina clustering. En el presente script se analizará 8 datasets utilizando **k-medias** y **clasificación jerárquica**.
  
#  Funciones implementadas
  
  Antes de realizar los correspondientes análisis a los distintos datasets, vamos a explicar brevemente las funciones implementadas que nos ayudaran a realizar lo anteriormente señalado.
  
### K-medias  
Es un método de agrupamiento, que tiene como objetivo la partición de un conjunto de n observaciones en k grupo.

```{r}
#****************************************************************************************
                                        #K-MEDIAS
#****************************************************************************************
kmedias <- function(df, columns, k, name){
  # Aplica el algoritmo de k-medias al dataframe.
  #
  # Args:
  #   df: Dataframe que se le desea aplicar k-medias.
  #   columns: Columnas del dataframe que se le desea aplicar k-medias.
  #   k: Número de clusters que se desean.
  #   name: Nombre del dataframe.
  #
  # Returns:
  #   Retorna el modelo generado.
  
  modelo.kmedias = kmeans(x = df[, columns], centers = k)
  
  #GRAFICAMOS LOS CLUSTERS
  plot(df[, columns], col = modelo.kmedias$cluster, main = paste(c("K-MEANS: ", name)))
  
  # Ahora graficamos los centroides 
  points(x = modelo.kmedias$centers[, columns], col = 4:8, pch = 19, cex = 3)
  
  return(modelo.kmedias)
}
```

### Clusterización jerárquica utilizando un K para determinar la altura
Dado un número de clusters k determinar la altura requerida para que tengamos el número de cluster k.

```{r}
#****************************************************************************************
                                  #CLUSTERS JERARQUICOS
#****************************************************************************************
#Dado un número de clusters k determinar la altura requerida para que tengamos el 
#número de cluster k.
clusterJD <- function(df, distancia, columns, method, k, name){
  # Aplica el algoritmo de clusterización utilizando un k para determinar
  # la altura.
  #
  # Args:
  #   df: Dataframe que se le desea aplicar k-medias.
  #   distancia: Matriz de distancias.
  #   columns: Columnas del dataframe que se le desea aplicar k-medias.
  #   method: Método deseado para aplicar el algoritmo (complete, single, average o ward.d).
  #   k: Número de clusters que se desean.
  #   name: Nombre del dataframe.
  #
  # Returns:
  #   Retorna el modelo generado.
  
  #Aplicamos cluster jerarquico utilizando el metodo correspondiente
  cluster = hclust(distancia, method = method)
  ############################################################
  #Determinar la altura requerida dado un numero de clusters k
  ############################################################
  #Cortamos el dendograma con K clases
  corteD = cutree(cluster, k = k)
  #Observamos la cantidad de clusters
  unique(corteD)
  #Graficamos los clusters
  plot(df[, columns], col = corteD, main = paste(c("Cluster jerarquico K: ", name)))
  
  return(corteD)
}

```

###  Clusterización jerárquica utilizando una medida de disimilaridad
Dada una altura h (una medida de disimilaridad) determinar el número de clusters que se obtienen.

```{r}
#Dada una altura h (una medida de disimilaridad) determinar el número de clusters que se obtienen.
clusterJH <- function(df, distancia, columns, method, h, name){
  # Aplica el algoritmo de clusterización utilizando un k para determinar
  # la altura.
  #
  # Args:
  #   df: Dataframe que se le desea aplicar k-medias.
  #   distancia: Matriz de distancias.
  #   columns: Columnas del dataframe que se le desea aplicar k-medias.
  #   method: Método deseado para aplicar el algoritmo (complete, single, average o ward.d).
  #   h:  Medida de disimilaridad.
  #   name: Nombre del dataframe.
  #
  # Returns:
  #   Retorna el modelo generado.
  
  #Aplicamos cluster jerarquico utilizando el metodo correspondiente
  cluster = hclust(distancia, method = method)
  #Graficamos el dendogram
  plot(cluster)
  
  ############################################################
  #Dada una altura h (una medida de disimilaridad) determinar 
  #el numero de clusters que se obtienen
  ############################################################
  # Cortamos por altura
  corteH = cutree(cluster, h = h)
  #Observamos la cantidad de clusters
  print(unique(corteH))
  #Graficamos los clusters
  plot(df[, columns], col = corteH, main = paste(c("Cluster jerarquico H: ", name)))
  
  return(corteH)
}

```

### Matriz de confusión
Es una herramienta que permite la visualización del desempeño de un algoritmo que se emplea en aprendizaje supervisado.

```{r}
#****************************************************************************************
#                                     MATRIZ DE CONFUSION
#****************************************************************************************
matrizconfusion = function(class, clusters){
  # Genera la matriz de confusión asociada al modelo.
  #
  # Args:
  #   class: Columna clase del dataframe.
  #   clusters: Clusters generados por el modelo.
  #
  # Returns:
  #   Retorna la matriz de confusión del modelo correspondiente.
  
  #Multiplico * 10 simplemente para poder reemplazar los numeros de forma correcta.
  clusters <- clusters * 10
  #Obtengo los valores unicos ordenados de la forma del modelo.
  ordermodel <- unique(clusters)
  
  #Cambio el nombre de los clusters ordenados crecientemente.
  for (i in 1:length(clusters)) {
    for (j in 1:length(ordermodel)) {
      if (clusters[i] == ordermodel[j]){
        clusters[i] <- j
      }
    }
  }
  #Guardo cuantas clases hay
  elem <- table(df$class)
  elem <- as.vector(elem)
  
  #Inicializo una tabla vacia con el tamano adecuado
  init <- table(df$class, clusters)
  for (h in 1:nrow(init)) {
    init[h,] <- 0
  }
  
  #M significa la posicion donde va empezar a leer en el modelo.
  m <- 1
  #z acumula las distancias a leer.
  z <- 0
  
  #Recorro clase por clase.
  for (i in 1:length(elem)){
    
    n <- elem[i]
    n <- n + z
    t <- table(clusters[m:n])
    c <- names(t)
    t <- as.vector(t)
    
    m <- n + 1
    z <- n
    for (j in 1:length(t)) {
      init[i, as.numeric(c[j])] <- t[j]
    }
    
  }#endfor que recorre
  return(init)
}#endfunction

```

### Precisión del modelo
La Precisión P de un modelo de predicción es la proporción del número total de predicciones que son correctas respecto al total. Se determina utilizando la ecuación: P = sum(diagonal(matriz de confusión))/ sum(todos los valores de la matriz de confusión).

```{r}
#****************************************************************************************
#                                 PRECISION DEL MODELO
#****************************************************************************************
precision <- function(m){
  # Calcula la precisión del modelo utilizando la matriz de confusión.
  #
  # Args:
  #   m: Matriz de confusión.
  #
  # Returns:
  #   Retorna la precisión del modelo.
  
#Precision
#P = (a+d)/(a+b+c+d)
  return(sum(diag(m)) /sum(m))
}

```

###  Mejor modelo
Selecciona el mejor modelo utilizando como criterio la mayor precisión.

```{r}
#****************************************************************************************
#                           MEJOR MODELO SEGUN LA PRECISION
#****************************************************************************************
bestmodel <- function(x){
  # Busca el mejor modelo.
  #
  # Args:
  #   x: Modelo con mayor precisión.
  #
  # Returns:
  #   Retorna el mejor modelo.
  
  
  if (x == 1){
    return("K-MEDIAS")
  }else if (x == 2){
    return("CLASIFICACION JERARQUICA K: METHOD COMPLETE")
  }else if (x == 3){
    return("CLASIFICACION JERARQUICA H: METHOD COMPLETE")
  }else if (x == 4){
    return("CLASIFICACION JERARQUICA K: METHOD SINGLE")
  }else if (x == 5){
    return("CLASIFICACION JERARQUICA H: METHOD SINGLE")
  }else if (x == 6){
    return("CLASIFICACION JERARQUICA K: METHOD AVERAGE")
  }else if (x == 7){
    return("CLASIFICACION JERARQUICA H: METHOD AVERAGE")
  }else if (x == 8){
    return("CLASIFICACION JERARQUICA K: METHOD WARD.D")
  }else{
    return("CLASIFICACION JERARQUICA H: METHOD WARD.D")
  }
}
```

# Encontrando estructuras
A continuación aplicaremos los siguientes objetivos a los datasets correspondientes:

* Usar métodos exploratorios. 

* Elaborar soluciones a problemas especí???cos de cada dataset. 

* Usar herramientas de clustering.

###  **a.csv**
* Preprocesamiento:
```{r}
name = "a.csv"
#Lectura de datos.
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/a.csv", header = F)
#Modificamos el nombre de las columnas por comodidad.
colnames(df) <- c("x","y","class")
#Coloco las clases del 1:n
df$class = as.numeric(df$class)
if (min(df$class) == 0){
  df$class <- df$class + 1
}

#Ordenamos la columna clase
df <- df[ order(df$class), ]
```
* Analisis exploratorio del dataset:
```{r}
#****************************************************************************************
                            #Analisis exploratorio del dataset
#****************************************************************************************
#Podemos observar que hay 3 columnas.
head(df)

#Observamos cuantos elementos hay de cada clase.
table(df$class)
#1     2    3 
#1000  1000 1000

#Grafico 
plot(df$x, df$y, xlab = "x", ylab = "y", main = name)
#Podemos observar 3 conglomerados

length(unique(df$class))
#Existen 3 clases.
```

* K-medias:
```{r}
#****************************************************************************************
                                       #K-MEDIAS
#****************************************************************************************
#Aplicamos k=3 ya que identificamos 3 conglomerados y existen 3 clases.
#kmedias(Dataframe, Columnas, K, name)
modeloK <- kmedias(df, 1:2, 3, name)

#Generamos la matriz de confusion
MatrixConfusionK <- matrizconfusion(df$class,modeloK$cluster)
MatrixConfusionK


#Calculamos la precision del modelo
PrecisionK <- precision(MatrixConfusionK)
PrecisionK

#Generamos la curva de ROC
modeloKROC <- roc(df$class, modeloK$cluster)
plot(modeloKROC,type="l",col="red")
```

* Clusters jerárquicos:
```{r}
#****************************************************************************************
                                  #CLUSTER JERARQUICOS
#****************************************************************************************
#Copy del dataset
datos = df
#Elimino la columna clase para realizar aprendizaje no supervisado.
datos$class <- NULL
#Convierto el dataframe en una matriz
datos= as.matrix(datos)
#Calculamos la matriz de distancia
distancia = dist(datos)
```

* Metódo complete:
```{r}
#--------------------------------------------------------------------------------------
                                    #METHOD COMPLETE
#--------------------------------------------------------------------------------------
#Dado un numero de clusters k determinar la altura requerida 
#para que tengamos el numero de cluster k.
clustersD <- clusterJD(df, distancia, 1:2, "complete", 3, name)
#Generamos la matriz de confusion
MatrixConfusionCJDC <- matrizconfusion(df$class, clustersD)
MatrixConfusionCJDC

elem <- table(df$class)
elem <- as.vector(elem)
init <- table(df$class, clustersD)
for (h in 1:nrow(init)) {
  init[h,] <- 0
}
m <- 1
z <- 0
for (i in 1:length(elem)){
  
  n <- elem[i]
  n <- n + z
  t <- table(clustersD[m:n])
  c <- names(t)
  t <- as.vector(t)
  
  m <- n + 1
  z <- n
  for (j in 1:length(t)) {
    init[i, as.numeric(c[j])] <- t[j]
  }
  
}#endfor que recorre
#Calculamos la precision del modelo
PrecisionDC <- precision(MatrixConfusionCJDC)
PrecisionDC

#Generamos la curva de ROC
modeloDC <- roc(df$class, clustersD)
plot(modeloDC,type="l",col="red")
#**********************************************************
#Dada una altura h (una medida de disimilaridad) determinar 
#el numero de clusters que se obtienen.
clustersH <- clusterJH(df, distancia, 1:2, "complete", 30, name)
#Generamos la matriz de confusion
MatrixConfusionCJHC <- matrizconfusion(df$class, clustersH)
MatrixConfusionCJHC

#Calculamos la precision del modelo
PrecisionHC <- precision(MatrixConfusionCJHC)
PrecisionHC

#Generamos la curva de ROC
modeloHC <- roc(df$class, clustersH)
plot(modeloHC,type="l",col="red")
```

* Metódo single:
```{r}
#--------------------------------------------------------------------------------------
                                    #METHOD SINGLE
#--------------------------------------------------------------------------------------
#Dado un numero de clusters k determinar la altura requerida 
#para que tengamos el numero de cluster k.
clustersD <- clusterJD(df, distancia, 1:2, "single", 3, name)
#Generamos la matriz de confusion
MatrixConfusionCJDS <- matrizconfusion(df$class, clustersD)
MatrixConfusionCJDS

#Calculamos la precision del modelo
PrecisionDS <- precision(MatrixConfusionCJDS)
PrecisionDS

#Generamos la curva de ROC
modeloDS <- roc(df$class, clustersD)
plot(modeloDS,type="l",col="red")
#**********************************************************
#Dada una altura h (una medida de disimilaridad) determinar 
#el numero de clusters que se obtienen.
clustersH <- clusterJH(df, distancia, 1:2, "single", 30, name)
#Generamos la matriz de confusion
MatrixConfusionCJHS <- matrizconfusion(df$class, clustersH)
MatrixConfusionCJHS

#Calculamos la precision del modelo
PrecisionHS <- precision(MatrixConfusionCJHS)
PrecisionHS

#Generamos la curva de ROC
modeloHS <- roc(df$class, clustersH)
plot(modeloHS,type="l",col="red")
```

* Metódo average:
```{r}
#--------------------------------------------------------------------------------------
                                    #METHOD AVERAGE
#--------------------------------------------------------------------------------------
#Dado un numero de clusters k determinar la altura requerida  
#para que tengamos el numero de cluster k.
clustersD <- clusterJD(df, distancia, 1:2, "average", 3, name)
#Generamos la matriz de confusion
MatrixConfusionCJDA <- matrizconfusion(df$class, clustersD)
MatrixConfusionCJDA

#Calculamos la precision del modelo
PrecisionDA <- precision(MatrixConfusionCJDA)
PrecisionDA

#Generamos la curva de ROC
modeloDA <- roc(df$class, clustersD)
plot(modeloDA,type="l",col="red")
#**********************************************************
#Dada una altura h (una medida de disimilaridad) determinar 
#el numero de clusters que se obtienen.
clustersH <- clusterJH(df, distancia, 1:2, "average", 15, name)
#Generamos la matriz de confusion
MatrixConfusionCJHA <- matrizconfusion(df$class, clustersH)
MatrixConfusionCJHA

#Calculamos la precision del modelo
PrecisionHA <- precision(MatrixConfusionCJHA)
PrecisionHA

#Generamos la curva de ROC
modeloHA <- roc(df$class, clustersH)
plot(modeloHA,type="l",col="red")
```

* Metódo ward.d:
```{r}
#--------------------------------------------------------------------------------------
                                    #METHOD ward.D
#--------------------------------------------------------------------------------------
#Dado un numero de clusters k determinar la altura requerida 
#para que tengamos el numero de cluster k.
clustersD <- clusterJD(df, distancia, 1:2, "ward.D", 3, name)
#Generamos la matriz de confusion
MatrixConfusionCJDW <- matrizconfusion(df$class, clustersD)
MatrixConfusionCJDW


#Calculamos la precision del modelo
PrecisionDW <- precision(MatrixConfusionCJDW)
PrecisionDW

#Generamos la curva de ROC
modeloDW <- roc(df$class, clustersD)
plot(modeloDW,type="l",col="red")
#**********************************************************
#Dada una altura h (una medida de disimilaridad) determinar 
#el numero de clusters que se obtienen.
clustersH <- clusterJH(df, distancia, 1:2, "ward.D", 10000, name)
#Generamos la matriz de confusion
MatrixConfusionCJHW <- matrizconfusion(df$class, clustersH)
MatrixConfusionCJHW

#Calculamos la precision del modelo
PrecisionHW <- precision(MatrixConfusionCJHW)
PrecisionHW

#Generamos la curva de ROC
modeloHW <- roc(df$class, clustersH)
plot(modeloHW,type="l",col="red")
```
# Mejor modelo
```{r}
#--------------------------------------------------------------------------------------
#                                 MEJOR MODELO
#--------------------------------------------------------------------------------------
precisiones <- c(PrecisionK, PrecisionDC, PrecisionHC, PrecisionDS, PrecisionHS, PrecisionDA, 
       PrecisionHA, PrecisionDW, PrecisionHW)
x <- which.max(precisiones)
mejormodelo <- bestmodel(x)
cat("El mejor modelo es: ", mejormodelo, ", que posee una precision de: ", precisiones[x], ".")


```