datos$class <- NULL
#Convierto el dataframe en una matriz
datos= as.matrix(datos)
#Calculamos la matriz de distancia
distancia = dist(datos)
clusterJ <- function(method, k, h){
#Aplicamos cluster jerarquico utilizando el metodo complete
cluster = hclust(distancia, method = method)
#Graficamos el dendogram
plot(cluster)
############################################################
#Determinar la altura requerida dado un numero de clusters k
############################################################
#Cortamos el dendograma con 3 clases
corte = cutree(cluster, k = k)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
############################################################
#Dada una altura h (una medida de disimilaridad) determinar
#el número de clústers que se obtienen
############################################################
# Cortamos por altura
corte = cutree(cluster, h = h)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
}
#--------------------------------------------------------------------------------------
#METHOD COMPLETE
#--------------------------------------------------------------------------------------
clusterJ("complete",3,30)
#Copy del dataset
datos = df
#Elimino la columna clase para realizar aprendizaje no supervisado.
datos$class <- NULL
#Convierto el dataframe en una matriz
datos= as.matrix(datos)
#Calculamos la matriz de distancia
distancia = dist(datos)
cluster = hclust(distancia, method = "complete")
plot(cluster)
corte = cutree(cluster, k = 2)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
plot(df, col = corte)
plot(cluster)
corte = cutree(cluster, h = 8.6)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 9)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 10)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 9.2)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 9.8)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 9.5)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 9.3)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
plot(df, col = corte)
cluster = hclust(distancia, method = "single")
#Graficamos el dendogram
plot(cluster)
############################################################
#Determinar la altura requerida dado un numero de clusters k
############################################################
#Cortamos el dendograma con 2 clases
corte = cutree(cluster, k = 2)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(df, col = corte)
corte = cutree(cluster, h = 1)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 100)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 20)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 10)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 5)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 3)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 2)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 2.5)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 2.9)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 3)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 4)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 3.5)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 3.7)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 3.8)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 3.75)
#Observamos la cantidad de clusters
unique(corte)
cluster = hclust(distancia, method = "average")
#Graficamos el dendogram
plot(cluster)
corte = cutree(cluster, k = 2)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(df, col = corte)
corte = cutree(cluster, h = 6)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
corte = cutree(cluster, h = 7)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
corte = cutree(cluster, h = 6.5)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 6.2)
#Observamos la cantidad de clusters
unique(corte)
cluster = hclust(distancia, method = "ward.D")
#Graficamos el dendogram
plot(cluster)
corte = cutree(cluster, h = 80)
#Observamos la cantidad de clusters
unique(corte)
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/guess.csv")
#Podemos observar que hay 2 columnas.
head(df)
colnames(df) <- c("x","y")
#****************************************************************************************
#Analisis exploratorio del dataset
#****************************************************************************************
#Podemos observar que hay 3 columnas.
head(df)
plot(df$x, df$y)
plot(df, pch = 19)
InerciaIC = rep(0, 30)
InerciaIC = rep(0, 30)
for (k in 1:30) {
grupos = kmeans(df, k)
InerciaIC[k] = grupos$tot.withinss
}
plot(InerciaIC, col = "blue", type = "b")
#Aplicamos k=2 ya que identificamos 2 conglomerados.
modelo.kmedias = kmeans(x = df[, c("x", "y")], centers = 2)
#GRAFICAMOS LOS CLUSTERS
plot(x = df$x, y = df$y, col = modelo.kmedias$cluster)
# Ahora graficamos los centroides
points(x = modelo.kmedias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
matrizconfusion <- table(df$class,modelo.kmedias$cluster,dnn=c("Clase", "Cluster"))
#Copy del dataset
datos = df
#Elimino la columna clase para realizar aprendizaje no supervisado.
datos$class <- NULL
#Convierto el dataframe en una matriz
datos= as.matrix(datos)
#Calculamos la matriz de distancia
distancia = dist(datos)
plot(cluster)
cluster = hclust(distancia, method = "complete")
#Graficamos el dendogram
plot(cluster)
corte = cutree(cluster, k = 2)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
plot(cluster)
corte = cutree(cluster, h = 100)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
points(x = modelo.kmedias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
#Aplicamos k=2 ya que identificamos 2 conglomerados.
modelo.kmedias = kmeans(x = df[, c("x", "y")], centers = 2)
#GRAFICAMOS LOS CLUSTERS
plot(x = df$x, y = df$y, col = modelo.kmedias$cluster)
# Ahora graficamos los centroides
points(x = modelo.kmedias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
#Copy del dataset
datos = df
#Elimino la columna clase para realizar aprendizaje no supervisado.
datos$class <- NULL
#Convierto el dataframe en una matriz
datos= as.matrix(datos)
#Calculamos la matriz de distancia
distancia = dist(datos)
#Aplicamos cluster jerarquico utilizando el metodo complete
cluster = hclust(distancia, method = "complete")
#Graficamos el dendogram
plot(cluster)
############################################################
#Determinar la altura requerida dado un numero de clusters k
############################################################
#Cortamos el dendograma con 2 clases
corte = cutree(cluster, k = 2)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
plot(cluster)
cluster = hclust(distancia, method = "single")
#Graficamos el dendogram
plot(cluster)
corte = cutree(cluster, h = 2)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
corte = cutree(cluster, h = 10)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 10)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
cluster = hclust(distancia, method = "average")
#Graficamos el dendogram
plot(cluster)
corte = cutree(cluster, h = 50)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
cluster = hclust(distancia, method = "single")
#Graficamos el dendogram
plot(cluster)
corte = cutree(cluster, h = 2)
#Observamos la cantidad de clusters
unique(corte)
corte = cutree(cluster, h = 10)
#Observamos la cantidad de clusters
unique(corte)
cluster = hclust(distancia, method = "ward.D")
#Graficamos el dendogram
plot(cluster)
corte = cutree(cluster, h = 30000)
#Observamos la cantidad de clusters
unique(corte)
#Graficamos los clusters
plot(x = df$x, y = df$y, col = corte)
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/h.csv")
View(df)
colnames(df) <- c("x","y","z","class")
table(df$class)
plot(df$x, df$y,df$z)
colnames(df) <- c("x","y","z","class")
plot(df$x, df$y,df$z)
plot(df$x, df$y)
plot(df)
install.packages("plot3D")
library(plot3D)
image2D(df)
scatter3D(df)
df$class <- NULL
scatter3D(df)
scatterplot3d(x, y, z, highlight.3d = TRUE, col.axis = "blue",
col.grid = "lightblue", main = "Helix", pch = 20)
install.packages("scatterplot3d")
install.packages("scatterplot3d")
install.packages("scatterplot3d")
library(scatterplot3d)
library(scatterplot3d)
#Lectura de datos.
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/h.csv")
#Modificamos el nombre de las columnas por comodidad.
colnames(df) <- c("x","y","z","class")
x <- df$x
y <- df$y
z <- df$z
scatterplot3d(x, y, z, highlight.3d = TRUE, col.axis = "blue",
col.grid = "lightblue", main = "Helix", pch = 20)
?plot3D
persp3D(x, y, z)
persp3d(x,y,z,col='green',
+ xlab="loss",ylab="alae",zlab="")
persp3d(x,y,z,col='green', xlab="loss",ylab="alae",zlab="")
install.packages("rgl")
library(rgl)
persp3d(x,y,z,col='green', xlab="loss",ylab="alae",zlab="")
persp3d(x,y,z)
persp3d(df$x,df$y,df$z,col='green', xlab="loss",ylab="alae",zlab="")
persp3d(df$x,df$y,df$z,col='green')
library(ggplot2)
install.packages("ggplot2")
ggplot2(df$x,df$y,df$z)
library(ggplot2)
ggplot(df$x,df$y,df$z)
ggplot(aes(df$x,df$y,df$z)
ggplot(aes(df$x,df$y,df$z)
ggplot(df,aes(df$x,df$y,df$z)
ggplot(df,aes(df$x,df$y,df$z))
#****************************************************************************************
ggplot(df,aes(df$x,df$y,df$z))
volcano3d <- melt(df)
install.packages("matplotlib")
install.packages("matplotlib")
persp3d(df$x,df$y,df$z,col='green', xlab="loss",ylab="alae",zlab="")
persp3D(x, y, z), highlight.3d = TRUE, col.axis = "blue",
col.grid = "lightblue", main = "Helix", pch = 20)
scatterplot3d(x, y, z, highlight.3d = TRUE, col.axis = "blue",
col.grid = "lightblue", main = "Helix", pch = 20)
library(rgl)
open3d()
persp3d(x, y, z, col = "red", alpha = 0.7, aspect = c(1, 1, 0.5))
grid3d(c("x", "y+", "z"))
x <- df$x
y <- df$y
z <- df$z
open3d()
persp3d(x, y, z, col = "red", alpha = 0.7, aspect = c(1, 1, 0.5))
persp3d(x, y, z, col = "red", alpha = 0.7)
grid3d(c("x", "y+", "z"))
persp3d(x, y, z, col = "red")
open3d()
persp3d(x, y, z, col = "red")
grid3d(c("x", "y+", "z"))
plot3d((x, y, z,
xlab, ylab, zlab, type = "p", col,
size, lwd, radius,
add = FALSE, aspect = !add,
xlim = NULL, ylim = NULL, zlim = NULL,
forceClipregion = FALSE, ...))
plot3d((x, y, z,
xlab, ylab, zlab, type = "p"))
plot3d((x, y, z, type = "p"))
plot3d(x, y, z, type = "p")
plot3d(x, y, z,  type = c("shade", "wire", "dots"))
plot3d(x, y, z, type = "p", col = rainbow(1000))
persp3d(x, y, z, col = df$class)
persp3d(x, y, z, col = as.vector(df$class))
persp3d(x, y, z, col = "red")
plot3d(x, y, z, type = "p", col = df$class)
plot3d(df$x, df$y, df$z, type = "o", col = df$class)
plot3d(df$x, df$y, df$z, type = "p", col = df$class)
plot3d(df$x, df$y, df$z, type = "p", col = df$class)
plot3d(df$x, df$y, df$z, type = "triangle", col = df$class)
plot3d(df$x, df$y, df$z, type = "triangle", col = df$class)
library(plot3d)
library(plot3d)
install.packages("plot3d")
plot3d(df$x, df$y, df$z, type = "triangle", col = df$class)
plot3d(df$x, df$y, df$z, type = "b", col = df$class)
plot3d(df$x, df$y, df$z,  type = c("shade", "wire", "dots"), col = df$class)
plot3d(df$x, df$y, df$z,  type = c("shade", "wire", "dots"), col = df$class)
plot3d(df$x, df$y, df$z, type = "t", col = df$class)
plot3d(df$x, df$y, df$z, type = "n", col = df$class)
plot3d(df$x, df$y, df$z, type = "l", col = df$class)
plot3d(df$x, df$y, df$z, type = "s", col = df$class)
plot3d(df$x, df$y, df$z, type = c("shade", "wire", "dots"), col = df$class)
plot3d(df$x, df$y, df$z, type = c("shade"), col = df$class)
plot3d(df$x, df$y, df$z, type = "s",size = 0.3, col = df$class)
plot3d(df$x, df$y, df$z, type = "s",size = 1, col = df$class)
plot3d(df$x, df$y, df$z, type = "s",size = 5, col = df$class)
plot3d(df$x, df$y, df$z, type = "s",size = 3, col = df$class)
plot3d(df$x, df$y, df$z, type = "p",size = 3, col = df$class)
plot3d(df$x, df$y, df$z, type = "p",size = 5, col = df$class)
plot3d(df$x, df$y, df$z, type = "p",size = 10, col = df$class)
plot3d(df$x, df$y, df$z, type = "s",size = 10, col = df$class)
plot3d(df$x, df$y, df$z, type = "s",size = 3, col = df$class)
plot3d(df$x, df$y, df$z, type = "s",size = 2, col = df$class)
library(rgl)
#Lectura de datos.
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/help.csv")
colnames(df) <- c("x","y","z","class")
plot3d(df$x, df$y, df$z, type = "s",size = 2, col = df$class)
plot3d(df$x, df$y, df$z, type = "s",size = 2, col = "rainbow")
plot3d(df$x, df$y, df$z, type = "s",size = 2, col = rainbow(1000))
source("funciones")
source("funciones.R")
source("src/funciones.R")
#Lectura de datos.
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/a_big.csv")
sdsd
s
s
getwd()
setwd("C:/Users/Eric/Desktop/AprendizajeNoSupervisado")
source("src/funciones.R")
df = read.csv(file = "data/a_big.csv")
kmedias(df,c("x", "y"),3)
kmedias <- function(df,col,k){
#Aplicamos k=3 ya que identificamos 3 conglomerados y existen 3 clases.
modelo.kmedias = kmeans(x = df[, col], centers = k)
#GRAFICAMOS LOS CLUSTERS
plot(x = df$x, y = df$y, col = modelo.kmedias$cluster)
# Ahora graficamos los centroides
points(x = modelo.kmedias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
}
kmedias(df,c("x", "y"),3)
kmedias <- function(df,col,k){
#Aplicamos k=3 ya que identificamos 3 conglomerados y existen 3 clases.
modelo.kmedias = kmeans(x = df[, col], centers = k)
}
kmedias(df,c("x", "y"),3)
kmedias <- function(df,k){
#Aplicamos k=3 ya que identificamos 3 conglomerados y existen 3 clases.
modelo.kmedias = kmeans(x = df[, c("x", "y")], centers = k)
#GRAFICAMOS LOS CLUSTERS
plot(x = df$x, y = df$y, col = modelo.kmedias$cluster)
# Ahora graficamos los centroides
points(x = modelo.kmedias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
}
kmedias(df,3)
df = read.csv(file = "data/a_big.csv")
colnames(df) <- c("x","y","class")
kmedias(df,3)
kmedias <- function(df,columns,k){
#Aplicamos k=3 ya que identificamos 3 conglomerados y existen 3 clases.
modelo.kmedias = kmeans(x = df[, columns], centers = k)
#GRAFICAMOS LOS CLUSTERS
plot(x = df$x, y = df$y, col = modelo.kmedias$cluster)
# Ahora graficamos los centroides
points(x = modelo.kmedias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
}
kmedias(df,[1:2],3)
kmedias(df,1:2,3)
kmedias <- function(df,columns,k){
#Aplicamos k=3 ya que identificamos 3 conglomerados y existen 3 clases.
modelo.kmedias = kmeans(x = df[, columns], centers = k)
#GRAFICAMOS LOS CLUSTERS
plot(x = df$x, y = df$y, col = modelo.kmedias$cluster)
# Ahora graficamos los centroides
points(x = modelo.kmedias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
return(modelo.kmedias$cluster)
}
x<-kmedias(df,1:2,3)
x
kmedias <- function(df,columns,k){
#Aplicamos k=3 ya que identificamos 3 conglomerados y existen 3 clases.
modelo.kmedias = kmeans(x = df[, columns], centers = k)
#GRAFICAMOS LOS CLUSTERS
plot(x = df$x, y = df$y, col = modelo.kmedias$cluster)
# Ahora graficamos los centroides
points(x = modelo.kmedias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
return(modelo.kmedias$cluster)
}
matrizconfusion <- function(class, clusters){
return(table(class, clusters, dnn=c("Clase", "Cluster")))
}
x<-matrizconfusion(df$class,clusters)
clusters <- kmedias(df,1:2,3)
x<-matrizconfusion(df$class,clusters)
x
table(dfclass, clusters, dnn=c("Clase", "Cluster"))
table(df$class, clusters, dnn=c("Clase", "Cluster"))
?table
row.names(x)
x<-table(df$class, clusters, dnn=c("Clase", "Cluster"))
row.names(x)
col.names(x)
row.names(x)
row.names(x)[2]
row.names(x)[,1]
colnames(x) <- c(0,1,2)
x
diag(x)
x[0]
x[0,]
x[0,0]
x[1]
x[,1]
x[,0]
x[,1]
x[,1:3]
clusters <- kmedias(df,1:2,3)
x<-table(df$class, clusters, dnn=c("Clase", "Cluster"))
x
x[,1]
x[1,]
max(x[1,])
max(x[,1])
nrow(x)
ncol(x)
x
